<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.0">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="MARDA SCIENCE Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="MARDA SCIENCE Blog Atom Feed"><title data-react-helmet="true">Benthic Fish Detection | MARDA SCIENCE</title><meta data-react-helmet="true" property="og:url" content="http://mardascience.com/docs/Analytics/doc0"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Benthic Fish Detection | MARDA SCIENCE"><meta data-react-helmet="true" name="description" content="This website is new and still under development, but please email daniel {at} mardascience {dot} com and I would be happy to talk with you!"><meta data-react-helmet="true" property="og:description" content="This website is new and still under development, but please email daniel {at} mardascience {dot} com and I would be happy to talk with you!"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="http://mardascience.com/docs/Analytics/doc0"><link data-react-helmet="true" rel="alternate" href="http://mardascience.com/docs/Analytics/doc0" hreflang="en"><link data-react-helmet="true" rel="alternate" href="http://mardascience.com/docs/Analytics/doc0" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.40303853.css">
<link rel="preload" href="/assets/js/runtime~main.eeea5c8f.js" as="script">
<link rel="preload" href="/assets/js/main.a96b659b.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#main" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle" type="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/MardaScience_logo_circle.png" alt="My Site Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/img/MardaScience_logo_circle.png" alt="My Site Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title">Marda Science</strong></a><a class="navbar__item navbar__link navbar__link--active" href="/docs/intro">What we do</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="react-toggle displayOnlyInLargeViewport_GrZ2 react-toggle--disabled" role="button" tabindex="-1"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img src="/img/MardaScience_logo_circle.png" alt="My Site Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/img/MardaScience_logo_circle.png" alt="My Site Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><strong class="navbar__title">Marda Science</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link navbar__link--active" href="/docs/intro">What we do</a></li><li class="menu__list-item"><a class="menu__link" href="/blog">Blog</a></li></ul></div></div></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_31aa"><div class="docSidebarContainer_3Kbt" role="complementary"><div class="sidebar_15mo"><div class="menu menu--responsive thin-scrollbar menu_Bmed"><button aria-label="Open menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_fgN0" width="24" height="24" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/docs/intro">Hi, we&#x27;re Maria and Dan ...</a></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Communications</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/Communications/doc1">Science and film-making</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/Communications/doc2">Plastic</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/Communications/doc3">Ocean Conservation</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/Communications/doc4">Fisheries</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Analytics</a><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/docs/Analytics/doc0">Benthic Fish Detection</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Analytics/doc1">Image Segmentation</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Analytics/doc3">MLOps: The Doodleverse</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Analytics/doc4">Object Detection</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Analytics/doc2">Sonar mapping</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Analytics/doc5">SandSnap: Citizen Science Beach Grain Size</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Analytics/doc6">Measuring nearshore waves from space</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Training</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/Training/doc0">Scientific Writing</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/Training/doc1">Environmental Image Analysis and Machine Vision</a></li></ul></li></ul></div></div></div><main class="docMainContainer_3ufF"><div class="container padding-vert--lg docItemWrapper_3FMP"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><header><h1 class="docTitle_3a4h">Benthic Fish Detection</h1></header><div class="markdown"><blockquote><p>This website is new and still under development, but please email daniel {at} mardascience {dot} com and I would be happy to talk with you!</p></blockquote><p>We develop a machine vision system for automated enumeration and sizing of in-
dividual benthic fish in underwater imagery. The system consists of 1) a single-pass
probabilistic object-detector model to find candidate regions where fish are likely to
be present, followed by 2) an image segmentation model to estimate the outline of
each individual fish. The system is applied to enumerating Round Goby (Neogobius
melanostomus) in Drop-camera as well as Autonomous Underwater Vehicle (AUV) in
imagery from Lake Michigan, USA. We find that a model cascade is advantageous over
applying a single model for the task. Both model outputs include an associated prob-
ability of detection. Hence the dual-model implementation provides two performance
metrics; a probability of fish identification and bounding box location which is useful
for error reporting for fish counts, and a separate probability of fish pixels, which is
additionally useful for error reporting for fish biomass.
The computational efficiency of the system is designed for on-board
quantification of fish in real-time.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="noisy-retinanet"></a>&quot;Noisy&quot; RetinaNet<a class="hash-link" href="#noisy-retinanet" title="Direct link to heading">#</a></h3><p>RetinaNet (Figure below) is a popular one-stage object detector, partly because it uses a
feature pyramid network to efficiently detect objects at multiple scales. Traditionally, image
pyramids have been used to detect objects with varying scales in an image, using feature
engineering practices (e.g. from HOG, Haar wavelets, etc), however this process is compute
and memory intensive. However, that practice has now been largely superceded by image
pyramiding based on hierarchical convolutional filters, called Featurized image pyramids.
The CNNs layers used have an inherently pyramidal hierarchy, and the model frameworks
are fully convolutional, which can takes an image of an any size and output proportionally
sized feature maps at multiple levels. RetinaNet uses a Feature Pyramid Network (FPN) built on top of ResNet-50
from which the final fully connected classification layer has
been removed, in a fully convolutional fashion to extract features at three spatial scales (and
corresponding pixel resolution). This feature extractor is referred to as the â€˜backboneâ€™ of
the model. In our implementation, we modify the backbone such that random
Gaussian noise is added to all three feature maps output by the backbone.</p><p>An FPN is used in conjunction with the backbone for constructing a multi-scalar feature
pyramid from an input image at a single resolution. This is achieved by connecting each of
the three ResNet-50 output feature maps at different scales (the bottom-up convolutional
layers in Figure below) with lateral connections to a top-down pathway that upsamples the
spatially coarser feature maps from higher pyramid levels. The lateral connections are used
to merge the top-down layers and the bottom-up layers with the same pixel size. The FPN
facilitates object detection at a range of scales.</p><p>The top-down pathway upsamples the spatially coarser feature maps from higher pyramid
levels, with residual (lateral) connections that merge the layers with the same spatial size. At
each of the prediction levels, there is a regression subnetwork, which estimates the precise
location of the bounding box of each fish, and a classification subnetwork that uses the
output of the coupled backbone-FCN to predict the probability of goby presence at each
spatial position</p><p>Each detection is probabilistic; a threshold probability is used to filter detections and is
used as a tunable parameter in model application. The framework for fish detection is based
on the RetinaNet model framework, based on a 3-layer feature pyramid network using a
ResNet-50 feature extractor. We modify the RetinaNet framework for the noisy underwater
environment by adding Gaussian noise to features extracted from imagery by ResNet-50. </p><p>Noise is only added during training, not during model evaluation or when
the model is used to make predictions on new sample imagery. The model is regularized
by the Gaussian noise, and is designed to make the model robust to noisy underwater envi-
ronments. Forcing the model to detect fish in the presence of significant noise ensures that
overfitting to extracted image features is minimized</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="gobynet-schematic"></a>GobyNet Schematic<a class="hash-link" href="#gobynet-schematic" title="Direct link to heading">#</a></h3><p>GobyNet model schematic, consisting of a bottom-up pathways that uses image
pyramiding to extract features at a hierarchy of levels, joined using residual connections to a
top-down pathway that merge the extracted features into a set of features that are passed to
both a classification and a regression subnetwork. The classification subnetwork determines
the class of the object and its likelihood, and the regression subnetwork estimates the corners
of the bounding box that surrounds the object.</p><p><img src="/assets/images/gobynet_arch-8588cd36d10c778ad16c5dd75f6f8b5f.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="training"></a>Training<a class="hash-link" href="#training" title="Direct link to heading">#</a></h3><p>Focal loss is a modification to the classical cross-entropy loss criterion for situations
where there is large class imbalance. Class imbalance in this scope means that only a small
proportion of any given scene are occupied by fish, even if Gobies are congregated in relatively
large clusters of up to a dozen of so individuals, owing to the small size of the fish with respect
to the large AUV image scene.</p><p>Effect of varying Î³ (a) and Î± (b) on Focal Loss. The effect of increasing Î³ is to reduce the relative loss for a given p , disproportionately for p &gt; .5. The effect of decreasing Î± is to reduce the relative loss for a given p , disproportionately for p &lt; .5.</p><p><img src="/assets/images/gobynet_gamma_alpha-6e788b5800b1c1f3707632e2a3cbe2f6.png"></p><p><img src="/assets/images/learnratesched_scratch-ann-e402aac6c0ff143831bd0b357dc299a1.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="performance"></a>Performance<a class="hash-link" href="#performance" title="Direct link to heading">#</a></h3><p>Example AUV imagery with gobies identified by green bounding boxes (these examples are some from the model training set</p><p><img src="/assets/images/Ex-bbox-creation-ann-de4a5936606eb46252000eeed2351d56.png"></p><p><img src="/assets/images/gobynet_modelout-retinanet-exs-e3870549ab3c37330db6c451e632a8a6.png"></p><p><img src="/assets/images/alpha-t0.5_alpha0.4res_100samples-ann-ad5abb7000ed95a8fd30c0eb406dd52e.png"></p><p><img src="/assets/images/best-t0.3_sigma0.2_gamma10res_100samples-ann-648486ab906b48fd44f8ba4617a15f35.png"></p><p><img src="/assets/images/sigma-t0.5_sigma0.6res_100samples-ann-fb34f547c24ac3755a0d281f9ab76f4c.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="residual-u-net-for-fish-detection"></a>Residual U-Net for Fish Detection<a class="hash-link" href="#residual-u-net-for-fish-detection" title="Direct link to heading">#</a></h3><p><img src="/assets/images/Fig5_gobynet_conceptual-562f6e1aebd12907d3099f55b152e3ae.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="training-data"></a>Training Data<a class="hash-link" href="#training-data" title="Direct link to heading">#</a></h3><p><img src="/assets/images/Fig1_goby_ex_intro_paper-af07dd2463736e1551da8165ec9b18e8.png"></p><p><img src="/assets/images/Fig3_Goby_ex_filt_paper-89437db0791730738bb57c62a8b3f96b.png"></p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_2LWZ" id="performance-1"></a>Performance<a class="hash-link" href="#performance-1" title="Direct link to heading">#</a></h3><p><img src="/assets/images/Fig6_Goby_meas_N_vs_est_CM-964f87de6f455a977e0a140a44139a55.png"></p><p><img src="/assets/images/Fig7_Goby_meas_vs_est_3metrics_test-19a254b72efef1e755b5dab609f891fc.png"></p><p><img src="/assets/images/Fig8_Goby_meas_vs_score_paper-8ec172628fb9c2c0177264e66ac30be9.png"></p></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/MARDAScience/web/edit/master/website/docs/Analytics/doc0.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" role="img" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-label="Edit page"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/Communications/doc4"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Fisheries</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/Analytics/doc1"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Image Segmentation Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#noisy-retinanet" class="table-of-contents__link">&quot;Noisy&quot; RetinaNet</a></li><li><a href="#gobynet-schematic" class="table-of-contents__link">GobyNet Schematic</a></li><li><a href="#training" class="table-of-contents__link">Training</a></li><li><a href="#performance" class="table-of-contents__link">Performance</a></li><li><a href="#residual-u-net-for-fish-detection" class="table-of-contents__link">Residual U-Net for Fish Detection</a></li><li><a href="#training-data" class="table-of-contents__link">Training Data</a></li><li><a href="#performance-1" class="table-of-contents__link">Performance</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 MARDA Science, LLC</div></div></div></footer></div>
<script src="/assets/js/runtime~main.eeea5c8f.js"></script>
<script src="/assets/js/main.a96b659b.js"></script>
</body>
</html>